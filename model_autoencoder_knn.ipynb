{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea8775e-45c9-47e0-b690-7e9cf7521845",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef70998b-6fc3-44ab-863e-1b3e0d8a0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torch\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a91681-d9d4-4bfb-9818-9d1f343136fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "color = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a832e-dc20-43e6-b176-8bd47a1de980",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5636cf-b378-4d82-9379-df3947780d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mentee survey data\n",
    "survey_results = pd.read_csv('./data/survey_results.csv')\n",
    "questions = survey_results.iloc[0]\n",
    "survey_results = survey_results.iloc[2:]\n",
    "id_questions = ['Q1', 'Q2']\n",
    "numeric_questions = ['Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q17_1', 'Q17_2', 'Q17_3', 'Q17_4', 'Q18_2', 'Q18_3', 'Q18_4', 'Q18_5', 'Q18_6', 'Q18_1', 'Q19_1', 'Q19_2', 'Q19_3', 'Q19_4', 'Q19_5', 'Q19_6', 'Q20_1', 'Q20_2', 'Q20_3', 'Q20_4', 'Q21_1', 'Q21_2', 'Q21_3', 'Q21_4', 'Q21_5', 'Q22_1', 'Q22_2', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28_1', 'Q29', 'Q30', 'Q31', 'Q32']\n",
    "# Eliminate empty names\n",
    "for col in id_questions:\n",
    "    survey_results = survey_results[survey_results[col].notna()]\n",
    "# Clean strings\n",
    "def clean(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    else:\n",
    "        return int(''.join(s for s in x if s.isdigit()))\n",
    "survey_results[numeric_questions] = survey_results[numeric_questions].applymap(clean)\n",
    "# Fill missing results\n",
    "knn = KNNImputer(n_neighbors=5)\n",
    "survey_results[numeric_questions] = knn.fit_transform(survey_results[numeric_questions])\n",
    "survey_results[numeric_questions] = survey_results[numeric_questions].astype(int)\n",
    "# Standardize\n",
    "survey_results[numeric_questions] = preprocessing.scale(survey_results[numeric_questions], axis=0)\n",
    "# Finalize\n",
    "survey_ids = np.array(survey_results[id_questions].applymap(lambda x: x.lower()))\n",
    "survey_ids = np.array([' '.join(x) for x in survey_ids])\n",
    "survey_ids = survey_ids.flatten()\n",
    "survey_results = np.array(survey_results[numeric_questions])\n",
    "# Remove duplicates by ids (might want to take last occurrence)\n",
    "_, first_occurrences = np.unique(survey_ids, return_index=True)\n",
    "mentee_survey_ids, mentee_survey_results = survey_ids[first_occurrences], survey_results[first_occurrences]\n",
    "\n",
    "# Load mentor survey data\n",
    "survey_results = pd.read_csv('./data/survey_results_mentors.csv')\n",
    "questions = survey_results.iloc[0]\n",
    "survey_results = survey_results.iloc[2:]\n",
    "id_questions = ['email address']\n",
    "# categorical_questions = ['Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'Q33']\n",
    "numeric_questions = ['Q3_1', 'Q3_2', 'Q3_3', 'Q3_4', 'Q3_5', 'Q3_6', 'Q3_7', 'Q3_8', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q16_1', 'Q16_2', 'Q16_3', 'Q16_4', 'Q17_2', 'Q17_3', 'Q17_4', 'Q17_5', 'Q17_6', 'Q17_1', 'Q18_1', 'Q18_2', 'Q18_3', 'Q18_4', 'Q18_5', 'Q18_6', 'Q19_1', 'Q19_2', 'Q19_3', 'Q19_4', 'Q20_1', 'Q20_2', 'Q20_3', 'Q20_4', 'Q20_5', 'Q21_1', 'Q21_2', 'Q22', 'Q23', 'Q24', 'Q25']\n",
    "# Eliminate empty names\n",
    "for col in id_questions:\n",
    "    survey_results = survey_results[survey_results[col].notna()]\n",
    "# Clean strings\n",
    "def clean(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    else:\n",
    "        return int(''.join(s for s in x if s.isdigit()))\n",
    "survey_results[numeric_questions] = survey_results[numeric_questions].applymap(clean)\n",
    "# Fill missing results\n",
    "knn = KNNImputer(n_neighbors=5)\n",
    "survey_results[numeric_questions] = knn.fit_transform(survey_results[numeric_questions])\n",
    "survey_results[numeric_questions] = survey_results[numeric_questions].astype(int)\n",
    "# Standardize\n",
    "survey_results[numeric_questions] = preprocessing.scale(survey_results[numeric_questions], axis=0)\n",
    "# Finalize\n",
    "survey_ids = np.array(survey_results[id_questions].applymap(lambda x: x.lower()))\n",
    "survey_ids = np.array([' '.join(x) for x in survey_ids])\n",
    "survey_ids = survey_ids.flatten()\n",
    "survey_results = np.array(survey_results[numeric_questions])\n",
    "# Remove duplicates by ids (might want to take last occurrence)\n",
    "_, first_occurrences = np.unique(survey_ids, return_index=True)\n",
    "mentor_survey_ids, mentor_survey_results = survey_ids[first_occurrences], survey_results[first_occurrences]\n",
    "\n",
    "# Load match data\n",
    "match_results = pd.read_csv('./data/matches.csv')\n",
    "mentor_cols = [' Mentor Email']\n",
    "mentee_cols = ['Mentee First Name', 'Mentee Last Name']\n",
    "match_results_mentor = np.array(match_results[mentor_cols].applymap(lambda x: x.lower()))\n",
    "match_results_mentor = np.array([' '.join(x) for x in match_results_mentor])\n",
    "match_results_mentee = np.array(match_results[mentee_cols].applymap(lambda x: x.lower()))\n",
    "match_results_mentee = np.array([' '.join(x) for x in match_results_mentee])\n",
    "match_results = np.stack([match_results_mentee, match_results_mentor], axis=1)\n",
    "\n",
    "# Take and filter to intersection of mentees\n",
    "mentee_intersection = np.intersect1d(match_results[:, 0], mentee_survey_ids)\n",
    "survey_idx = [n in mentee_intersection for n in mentee_survey_ids]\n",
    "mentee_survey_ids = mentee_survey_ids[survey_idx]\n",
    "mentee_survey_results = mentee_survey_results[survey_idx]\n",
    "match_idx = [n in mentee_intersection for n in match_results[:, 0]]\n",
    "match_results = match_results[match_idx, :]\n",
    "\n",
    "# Take and filter to intersection of mentors\n",
    "mentor_intersection = np.intersect1d(match_results[:, 1], mentor_survey_ids)\n",
    "survey_idx = [n in mentor_intersection for n in mentor_survey_ids]\n",
    "mentor_survey_ids = mentor_survey_ids[survey_idx]\n",
    "mentor_survey_results = mentor_survey_results[survey_idx]\n",
    "match_idx = [n in mentor_intersection for n in match_results[:, 1]]\n",
    "match_results = match_results[match_idx, :]\n",
    "\n",
    "# Take and filter to intersection of mentees (again, since mentor filtering could exclude a few)\n",
    "mentee_intersection = np.intersect1d(match_results[:, 0], mentee_survey_ids)\n",
    "survey_idx = [n in mentee_intersection for n in mentee_survey_ids]\n",
    "mentee_survey_ids = mentee_survey_ids[survey_idx]\n",
    "mentee_survey_results = mentee_survey_results[survey_idx]\n",
    "\n",
    "# Unique mentors\n",
    "mentors, match_results[:, 1] = np.unique(match_results[:, 1], return_inverse=True)\n",
    "mentor_survey_ids = np.array([np.argwhere(n == mentors)[0] for n in mentor_survey_ids]).flatten()\n",
    "# Unique mentees\n",
    "mentees, match_results[:, 0] = np.unique(match_results[:, 0], return_inverse=True)\n",
    "mentee_survey_ids = np.array([np.argwhere(n == mentees)[0] for n in mentee_survey_ids]).flatten()\n",
    "\n",
    "# Formulate vars\n",
    "matches = match_results.astype(int)\n",
    "matches_outcome = np.ones(len(matches)).astype(float)  # Presence data\n",
    "mentee_features = mentee_survey_results.astype(float)\n",
    "mentee_features_ids = mentee_survey_ids\n",
    "mentor_features = mentor_survey_results.astype(float)\n",
    "mentor_features_ids = mentor_survey_ids\n",
    "# mentees\n",
    "# mentors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13df2df-805f-46fc-a31b-bb5729899799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test\n",
    "train_idx = range(int(.8 * len(mentees)))\n",
    "test_idx = list(set(range(len(mentees))) - set(train_idx))\n",
    "sort_idx = np.argsort(feature_ids)  # TODO, Further shuffle matches\n",
    "mentee_features, mentee_features_test = mentee_features[sort_idx][train_idx], mentee_features[sort_idx][test_idx]\n",
    "feature_ids, feature_ids_test = feature_ids[sort_idx][train_idx], feature_ids[sort_idx][test_idx]\n",
    "idx = [(mentee in feature_ids) for mentee in matches[:, 0]]\n",
    "tidx = [(mentee in feature_ids_test) for mentee in matches[:, 0]]\n",
    "matches, matches_test = matches[idx], matches[tidx]\n",
    "matches_outcome, matches_outcome_test = matches_outcome[idx], matches_outcome[tidx]\n",
    "# Finalize dim variables\n",
    "num_mentors = len(mentors)\n",
    "num_mentees = len(train_idx)\n",
    "num_matches = len(matches)\n",
    "num_features = mentee_features.shape[1]\n",
    "num_mentors_test = len(mentors)\n",
    "num_mentees_test = len(test_idx)\n",
    "num_matches_test = len(matches_test)\n",
    "num_features_test = mentee_features.shape[1]\n",
    "\n",
    "# Implement fake negatives (optional)\n",
    "fake_percentage = .5\n",
    "fake_num = int(fake_percentage * num_matches / (1 - fake_percentage))\n",
    "fake_mentees = np.random.choice(range(num_mentees), fake_num, replace=True)\n",
    "fake_mentors = np.random.choice(range(num_mentors), fake_num, replace=True)\n",
    "fake_matches = np.stack((fake_mentees, fake_mentors), axis=1)\n",
    "fake_outcome = np.zeros(fake_num)\n",
    "# Append\n",
    "matches = np.concatenate((matches, fake_matches), axis=0)\n",
    "matches_outcome = np.concatenate((matches_outcome, fake_outcome), axis=0)\n",
    "num_matches = len(matches)\n",
    "\n",
    "# Cast to type\n",
    "matches = torch.Tensor(matches.astype(float)).int()\n",
    "matches_outcome = torch.Tensor(matches_outcome).float()\n",
    "matches_test = torch.Tensor(matches_test.astype(float)).int()\n",
    "matches_outcome_test = torch.Tensor(matches_outcome_test).float()\n",
    "mentee_features = torch.Tensor(mentee_features).float()\n",
    "mentee_features_test = torch.Tensor(mentee_features_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5957b4-52c5-4720-b199-70cbe4936e81",
   "metadata": {},
   "source": [
    "# Autoencoder KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88d4a78-83b3-4f2a-b860-2c1569efaa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Variables\n",
    "dim_embedding = 10\n",
    "epochs = 2001\n",
    "batches = 20\n",
    "lr = .001\n",
    "epoch_pd = 200\n",
    "batch_size = 64\n",
    "batches = int(len(matches)/batch_size)\n",
    "\n",
    "# Autoencoder\n",
    "model = LatentModel(num_features, latent_dim=dim_embedding)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f48bd01-4f34-4b02-9c19-75c27e25efe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 1.6940064430236816\n",
      "Epoch: 200 \tLoss: 0.033134836703538895\n",
      "Epoch: 400 \tLoss: 0.020022958517074585\n",
      "Epoch: 600 \tLoss: 0.018427524715662003\n",
      "Epoch: 800 \tLoss: 0.01828780397772789\n",
      "Epoch: 1000 \tLoss: 0.016249192878603935\n",
      "Epoch: 1200 \tLoss: 0.02792241796851158\n",
      "Epoch: 1400 \tLoss: 0.01245100423693657\n",
      "Epoch: 1600 \tLoss: 0.014294893480837345\n",
      "Epoch: 1800 \tLoss: 0.018847832456231117\n",
      "Epoch: 2000 \tLoss: 0.029806623235344887\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(batches):\n",
    "        # Train\n",
    "        optimizer.zero_grad()\n",
    "        idx = np.random.choice(range(num_mentees), batch_size, replace=False)\n",
    "        input_data = mentee_features[idx]\n",
    "        _, reconst = model(input_data)\n",
    "        loss = criterion(reconst, input_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % epoch_pd == 0:\n",
    "        print(f'Epoch: {epoch}', end=' \\t')\n",
    "        print(f'Loss: {float(loss)}')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f286a4a7-e188-4bb8-a370-2ccb7952f0bc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79ff600e-6fb8-45a1-87ba-5d17d1d8fdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9940476190476191\n",
      "0.005952380952380952\n"
     ]
    }
   ],
   "source": [
    "# Make KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors=10)\n",
    "feat = model(mentee_features)[0].detach().cpu().numpy()\n",
    "labels = matches[:, 1].numpy()\n",
    "KNN.fit(feat[matches[:, 0]], labels)\n",
    "\n",
    "# Predict\n",
    "predicted = KNN.kneighbors(feat[matches[:, 0]])[1]\n",
    "predicted = np.vectorize(lambda x: labels[int(x)])(predicted)[:, :5]\n",
    "actual = matches[:, 1]\n",
    "print(sum([int(ex) in pr for ex, pr in zip(actual, predicted)]) / len(actual))\n",
    "\n",
    "feat_test = model(mentee_features_test)[0].detach().cpu().numpy()\n",
    "predicted = KNN.kneighbors(feat_test[matches_test[:, 0] - len(train_idx)])[1]\n",
    "predicted = np.vectorize(lambda x: labels[int(x)])(predicted)[:, :5]\n",
    "actual = matches[:, 1]\n",
    "print(sum([int(ex) in pr for ex, pr in zip(actual, predicted)]) / len(actual))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
